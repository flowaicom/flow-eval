{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use APIs that are openai-compatible (Together, OpenAI, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flow_eval.models.openai:Successfully initialized OpenAI!\n",
      "INFO:flow_eval.models.openai:Initiating batched OpenAI async requests\n",
      "100%|██████████| 6/6 [00:00<00:00, 87685.80it/s]\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:flow_eval.flow_eval:[EvalOutput(feedback='The generated response is mostly consistent with the provided context. The response accurately explains the solution to the customer\\'s issue with pushing large files to their Git repository, using Git Large File Storage (LFS). The steps provided are clear and concise, and they are directly supported by the context. The only minor inconsistency is the inclusion of the sentence \"By using Git LFS, you\\'ll be able to push files larger than GitHub\\'s 100 MB limit, as LFS will handle them appropriately.\" which is not explicitly mentioned in the context, but it is a logical conclusion based on the information provided. Overall, the response is well-structured and easy to follow, making it a reliable solution for the customer\\'s issue.', score=4), EvalOutput(feedback='The generated response is mostly inconsistent with the provided context. While it includes some information from the context, it introduces a substantial amount of hallucinated or fabricated details that deviate from the context. The response provides confusing steps, and the language used is unclear. The tone is also negative, stating that the user will \"definitely encounter the \\'Remote origin already exists\\' error\" after making the changes, which is not a helpful or accurate statement.\\n\\nThe response also contains minor inaccuracies, such as the suggestion to replace \\'new-url\\' with \"the exact same URL you\\'re currently using\" in step 2, which is not necessary and may cause confusion. Additionally, the response suggests removing a remote with a different name, which is not a recommended solution.\\n\\nThe response does not provide a clear and concise solution to the problem, and the language used is not professional or helpful. Overall, the response is not faithful to the context and does not provide a useful solution to the user\\'s problem.', score=2), EvalOutput(feedback='The response is well-structured and easy to follow, providing a clear step-by-step guide on how to safely revert a commit in Git. The language used is technical and accurate, demonstrating a good understanding of the context. The response stays within the boundaries of the provided context, using only the information presented to create a solution. The only minor inconsistency is the inclusion of a general reminder to ensure the correct branch is being worked on, which is not directly related to the specific task of reverting a commit. However, this is a minor point and does not detract from the overall quality of the response.\\n\\nThe response is mostly consistent with the provided context, with only minor and inconsequential inconsistencies or fabrications. The vast majority of the content is supported by the context, making it a strong candidate for a high score.', score=4), EvalOutput(feedback=\"The generated response is mostly inconsistent with the provided context. While it mentions some of the steps from the original context, it introduces a substantial amount of hallucinated or fabricated details that deviate from the context. The response claims that Git automatically cleans up and removes sensitive data from the repository's history, which is not supported by the original context. Additionally, it states that collaborators do not need to rebase or adjust their branches, which is also not mentioned in the original context. The response also includes statements that are not supported by the context, such as Git automatically updating the repository and removing cached views and references to sensitive data.\\n\\nThe response lacks faithfulness to the original context and includes significant amount of fabricated information that contradicts or is not supported by the context. The minor inconsistencies and fabrications in the response are not inconsequential and significantly impact the overall accuracy and reliability of the response.\", score=2), EvalOutput(feedback='The generated response is mostly consistent with the provided context. The response accurately summarizes the steps to resolve merge conflicts in Git, and the language used is clear and concise. The response also includes a helpful tip to minimize merge conflicts in the future. However, the response could be improved by providing more specific examples of how to resolve conflicts, and by including a more detailed explanation of the conflict markers.\\n\\nThe response does not contain any hallucinated or fabricated information that is not supported by the context. The language used is professional and technical, and the response is well-organized and easy to follow.\\n\\nOverall, the response is a good effort, but it could be improved by providing more specific examples and a more detailed explanation of the conflict markers.', score=4), EvalOutput(feedback='The response is mostly consistent with the provided context. The steps provided to connect a local repository to a new remote repository are accurate and follow the same syntax and structure as the context. The response does not contain any significant amount of hallucinated or fabricated information that contradicts or deviates from the context. However, it could be improved by providing more detailed explanations and examples to support the steps.\\n\\nThe response is faithful to the context, but it could be more comprehensive and detailed. The provided steps are clear and concise, but they do not provide additional information or insights that could help the user better understand the process.\\n\\nThe response is mostly consistent with the provided context, and it does not contain any significant amount of hallucinated or fabricated information. However, it could be improved by providing more detailed explanations and examples to support the steps.\\n\\nThe response is mostly consistent with the provided context, and it does not contain any significant amount of hallucinated or fabricated information. However, it could be improved by providing more detailed explanations and examples to support the steps.\\n\\nThe response is mostly consistent with the provided context, and it does not contain any significant amount of hallucinated or fabricated information. However, it could be improved by providing more detailed explanations and examples to support the steps.', score=4)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EvalOutput(feedback='The generated response is mostly consistent with the provided context. The response accurately explains the solution to the customer\\'s issue with pushing large files to their Git repository, using Git Large File Storage (LFS). The steps provided are clear and concise, and they are directly supported by the context. The only minor inconsistency is the inclusion of the sentence \"By using Git LFS, you\\'ll be able to push files larger than GitHub\\'s 100 MB limit, as LFS will handle them appropriately.\" which is not explicitly mentioned in the context, but it is a logical conclusion based on the information provided. Overall, the response is well-structured and easy to follow, making it a reliable solution for the customer\\'s issue.', score=4), EvalOutput(feedback='The generated response is mostly inconsistent with the provided context. While it includes some information from the context, it introduces a substantial amount of hallucinated or fabricated details that deviate from the context. The response provides confusing steps, and the language used is unclear. The tone is also negative, stating that the user will \"definitely encounter the \\'Remote origin already exists\\' error\" after making the changes, which is not a helpful or accurate statement.\\n\\nThe response also contains minor inaccuracies, such as the suggestion to replace \\'new-url\\' with \"the exact same URL you\\'re currently using\" in step 2, which is not necessary and may cause confusion. Additionally, the response suggests removing a remote with a different name, which is not a recommended solution.\\n\\nThe response does not provide a clear and concise solution to the problem, and the language used is not professional or helpful. Overall, the response is not faithful to the context and does not provide a useful solution to the user\\'s problem.', score=2), EvalOutput(feedback='The response is well-structured and easy to follow, providing a clear step-by-step guide on how to safely revert a commit in Git. The language used is technical and accurate, demonstrating a good understanding of the context. The response stays within the boundaries of the provided context, using only the information presented to create a solution. The only minor inconsistency is the inclusion of a general reminder to ensure the correct branch is being worked on, which is not directly related to the specific task of reverting a commit. However, this is a minor point and does not detract from the overall quality of the response.\\n\\nThe response is mostly consistent with the provided context, with only minor and inconsequential inconsistencies or fabrications. The vast majority of the content is supported by the context, making it a strong candidate for a high score.', score=4), EvalOutput(feedback=\"The generated response is mostly inconsistent with the provided context. While it mentions some of the steps from the original context, it introduces a substantial amount of hallucinated or fabricated details that deviate from the context. The response claims that Git automatically cleans up and removes sensitive data from the repository's history, which is not supported by the original context. Additionally, it states that collaborators do not need to rebase or adjust their branches, which is also not mentioned in the original context. The response also includes statements that are not supported by the context, such as Git automatically updating the repository and removing cached views and references to sensitive data.\\n\\nThe response lacks faithfulness to the original context and includes significant amount of fabricated information that contradicts or is not supported by the context. The minor inconsistencies and fabrications in the response are not inconsequential and significantly impact the overall accuracy and reliability of the response.\", score=2), EvalOutput(feedback='The generated response is mostly consistent with the provided context. The response accurately summarizes the steps to resolve merge conflicts in Git, and the language used is clear and concise. The response also includes a helpful tip to minimize merge conflicts in the future. However, the response could be improved by providing more specific examples of how to resolve conflicts, and by including a more detailed explanation of the conflict markers.\\n\\nThe response does not contain any hallucinated or fabricated information that is not supported by the context. The language used is professional and technical, and the response is well-organized and easy to follow.\\n\\nOverall, the response is a good effort, but it could be improved by providing more specific examples and a more detailed explanation of the conflict markers.', score=4), EvalOutput(feedback='The response is mostly consistent with the provided context. The steps provided to connect a local repository to a new remote repository are accurate and follow the same syntax and structure as the context. The response does not contain any significant amount of hallucinated or fabricated information that contradicts or deviates from the context. However, it could be improved by providing more detailed explanations and examples to support the steps.\\n\\nThe response is faithful to the context, but it could be more comprehensive and detailed. The provided steps are clear and concise, but they do not provide additional information or insights that could help the user better understand the process.\\n\\nThe response is mostly consistent with the provided context, and it does not contain any significant amount of hallucinated or fabricated information. However, it could be improved by providing more detailed explanations and examples to support the steps.\\n\\nThe response is mostly consistent with the provided context, and it does not contain any significant amount of hallucinated or fabricated information. However, it could be improved by providing more detailed explanations and examples to support the steps.\\n\\nThe response is mostly consistent with the provided context, and it does not contain any significant amount of hallucinated or fabricated information. However, it could be improved by providing more detailed explanations and examples to support the steps.', score=4)]\n"
     ]
    }
   ],
   "source": [
    "from flow_eval import OpenAIModel, EvalInput, AsyncFlowJudge\n",
    "\n",
    "from flow_eval.metrics import RESPONSE_FAITHFULNESS_5POINT\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# model = OpenAIModel(exec_async=True)\n",
    "\n",
    "model = OpenAIModel(\n",
    "    _model_id=\"meta-llama/Llama-3-8b-chat-hf\",\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    key_var=\"TOGETHER_API_KEY\",\n",
    "    exec_async=True\n",
    ")\n",
    "\n",
    "# Initialize the judge\n",
    "faithfulness_judge = AsyncFlowJudge(\n",
    "    metric=RESPONSE_FAITHFULNESS_5POINT,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "with open(\"/home/bernardo/repos/flow-eval/examples/sample_data/csr_assistant.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a list of inputs and outputs\n",
    "inputs_batch = [\n",
    "    [\n",
    "        {\"query\": sample[\"query\"]},\n",
    "        {\"context\": sample[\"context\"]},\n",
    "    ]\n",
    "    for sample in data\n",
    "]\n",
    "outputs_batch = [{\"response\": sample[\"response\"]} for sample in data]\n",
    "\n",
    "# Create a list of EvalInput\n",
    "eval_inputs_batch = [EvalInput(inputs=inputs, output=output) for inputs, output in zip(inputs_batch, outputs_batch)]\n",
    "\n",
    "# Run the evaluation\n",
    "async def main():\n",
    "    results = await faithfulness_judge.async_batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "    return results\n",
    "\n",
    "results = asyncio.run(main())\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
